{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(file_name):\n",
    "  # Opening JSON file\n",
    "  with open(file_name) as json_file:\n",
    "    data = json.load(json_file)\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjects = ['P01', 'P04', 'P06','P07', 'P09','P11','P12'] \n",
    "test_subjects = ['P13']\n",
    "# discard data collected from P14. He/She was sleeping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event IDs: [  11   12   13     21   22   23     31   32   33    41   42\n",
    "   43    111  112  113 121  122  123    131  132  133 \n",
    "  141  142  143   211  212  213   221  222  223   231  232\n",
    "  233  241  242  243 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each subject 36 events, and each event has 60 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['P01', 'P04', 'P06', 'P07', 'P09', 'P11', 'P12'])\n",
      "dict_keys(['P13', 'P14'])\n",
      "36\n",
      "3175\n"
     ]
    }
   ],
   "source": [
    "train_dict = get_dict('train_3175.json')\n",
    "test_dict = get_dict('test_3175.json')\n",
    "\n",
    "print(train_dict.keys())\n",
    "print(test_dict.keys())\n",
    "\n",
    "print(len(train_dict['P01']))\n",
    "# P01 subject key, and 112 is event key, value is 60 points\n",
    "print(len(train_dict['P01']['112']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Predict whether the music which subjects are listening to have lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Subjects were listening to different types of music. In this task, our model predicts whether the music which subject were listening to has lyrics or not. The event ID indicates whether a piece of music has lyrics or not. According to the dataset, if the number before the last digit of event ID is less than 5, the music includes lyrics. If not, the music does not include lyrics. \n",
    "\n",
    "###### We label 1 if music has lyrics, 0 if music does not have lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        X_train.append(train_dict[i][e])\n",
    "        if int(e[:-1]) < 5:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(252, 3175)\n",
      "(252,)\n",
      "[[-1.69119553e-06 -1.70719092e-06 -1.70571593e-06 ... -2.82413139e-06\n",
      "  -2.99672046e-06 -3.12866468e-06]\n",
      " [ 2.51033489e-07  8.28635578e-08 -5.07200770e-08 ...  1.46581121e-06\n",
      "   1.40723283e-06  1.34682366e-06]\n",
      " [ 2.32050990e-07  2.68842057e-07  2.88497187e-07 ... -2.18505816e-07\n",
      "  -3.29256592e-07 -4.77714800e-07]\n",
      " ...\n",
      " [-4.31661990e-07 -5.58612147e-07 -6.61924365e-07 ...  1.04634445e-06\n",
      "   1.01671609e-06  8.77562638e-07]\n",
      " [-3.99281651e-08  1.19493492e-07  1.76883307e-07 ...  1.70887086e-06\n",
      "   1.73587248e-06  1.74346539e-06]\n",
      " [-5.51766142e-07 -5.23061655e-07 -4.25232392e-07 ... -1.94006106e-07\n",
      "  -1.97847205e-07 -1.63716152e-07]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross validation accuracy: 0.610980\n"
     ]
    }
   ],
   "source": [
    "# 5-fold cross validation\n",
    "score_lsqrs = cross_val_score(clf.fit(X_train, y_train), X_train, y_train, cv = 5)\n",
    "\n",
    "print(\"cross validation accuracy: %f\" % np.mean(score_lsqrs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Check accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on train set is 0.9404761904761905\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(train_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "pred=np.array(pred).astype(int)\n",
    "print(\"Model's accuracy on train set is\",np.sum(pred==y_train)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Apply model to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set is 0.6111111111111112\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "pred=[]\n",
    "for i in test_subjects:\n",
    "    eventIDs=test_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(test_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "        if int(e[:-1])<5:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "pred=np.array(pred).astype(int)\n",
    "y_test=np.array(y_test)\n",
    "print(\"Model's accuracy on test set is\",np.sum(pred==y_test)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Try another machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\yifan\\anaconda3\\lib\\site-packages (3.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from lightgbm) (1.20.3)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.1)\n",
      "Requirement already satisfied: wheel in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from lightgbm) (0.37.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\yifan\\anaconda3\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Check accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model's accuracy on train set is 1.0\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(train_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "pred=np.array(pred).astype(int)\n",
    "print(\"LightGBM Model's accuracy on train set is\",np.sum(pred==y_train)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Check accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Model's accuracy on test set is 0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "pred=[]\n",
    "for i in test_subjects:\n",
    "    eventIDs=test_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(test_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "        if int(e[:-1])<5:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "pred=np.array(pred).astype(int)\n",
    "y_test=np.array(y_test)\n",
    "print(\"LightGBM Model's accuracy on test set is\",np.sum(pred==y_test)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It seems that Light GBM is a better model, so we decide to mainly use Light GBM to implement the following predictive tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Predict whether stimuli have cue clicks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Stimuli in this dataset were presented to the participants in several conditions while EEG was recorded. This task predicts whether stimulus was presented with cue clicks or not. The last digit of event ID indicates stimulus' condition. If this digit is less than 3, the stimulus was presented with cue clicks. If not, the stimulus was presented without cue clicks.\n",
    "###### We label 1 if the stimulus was presented with cue clicks and 0 if the stimulus was presented without cue clicks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        X_train.append(train_dict[i][e])\n",
    "        if int(e[-1]) < 3:\n",
    "            y_train.append(1)\n",
    "        else:\n",
    "            y_train.append(0)\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Check accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on train set is 1.0\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(train_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "pred=np.array(pred).astype(int)\n",
    "print(\"Model's accuracy on train set is\",np.sum(pred==y_train)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Check accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set is 0.8055555555555556\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "pred=[]\n",
    "for i in test_subjects:\n",
    "    eventIDs=test_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(test_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "        if int(e[-1])<3:\n",
    "            y_test.append(1)\n",
    "        else:\n",
    "            y_test.append(0)\n",
    "pred=np.array(pred).astype(int)\n",
    "y_test=np.array(y_test)\n",
    "print(\"Model's accuracy on test set is\", np.sum(pred==y_test)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Predict stimuli's conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### More specifically, the stimulu were presented in these four conditions. \n",
    "1. Stimulus perception with cue clicks\n",
    "\n",
    "2. Stimulus imagination with cue clicks\n",
    "\n",
    "3. Stimulus imagination without cue clicks\n",
    "\n",
    "4. Stimulus imagination without cue clicks, with additional feedback from participants after each trial\n",
    "\n",
    "We only include the first three conditions in our data since the fourth condition is affected by feedback after trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Get data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        X_train.append(train_dict[i][e])\n",
    "        y_train.append(int(e[-1]))\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = lgb.LGBMClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Check accuracy on train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on train set is 1.0\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for i in train_subjects:\n",
    "    eventIDs=train_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(train_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "pred=np.array(pred).astype(int)\n",
    "print(\"Model's accuracy on train set is\",np.sum(pred==y_train)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Check accuracy on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's accuracy on test set is 0.6388888888888888\n"
     ]
    }
   ],
   "source": [
    "y_test=[]\n",
    "pred=[]\n",
    "for i in test_subjects:\n",
    "    eventIDs=test_dict[i].keys()\n",
    "    for e in eventIDs:\n",
    "        sample = np.array(test_dict[i][e]).reshape(1,-1)\n",
    "        pred.append(clf.predict(sample)[0])\n",
    "        y_test.append(int(e[-1]))\n",
    "pred=np.array(pred).astype(int)\n",
    "y_test=np.array(y_test)\n",
    "print(\"Model's accuracy on test set is\",np.sum(pred==y_test)/len(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "The overall performance of our predictive model is not as good as expected. The performance of train set is much higher than the performance of test set. Our model might have overfitting problems. The reason might be that we did not properly encode the EEG data as model input. The size of the dataset might also be a problem. We only have data from nine subjects. In order to have a better model, we need data from more subjects."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f23913d9230df67bc23a51356841fd38e81e27d09455160e8fc0905f1720ab7"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
