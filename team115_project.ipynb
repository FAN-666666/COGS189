{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import pathlib\n",
    "import mne\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this can show graph in new page!\n",
    "# useful!\n",
    "# matplotlib.use('Qt5Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fif(name):\n",
    "  \"\"\"\n",
    "   use mne read fif data\n",
    "   return back raw data\n",
    "  \"\"\"\n",
    "  fname = 'OpenMIIR-RawEEG_v1/'+ name + '-raw.fif'\n",
    "  raw = mne.io.read_raw_fif(fname, preload=True)\n",
    "  return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we write our own read fif function by using mne\n",
    "raw = read_fif('P01')\n",
    "raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn our datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use P01 subject to show how we do the data pre-processing part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check raw data plot \n",
    "fig = raw.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to know how many events do we have\n",
    "events = mne.find_events(raw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show events graph\n",
    "# we want to know each events happen times\n",
    "fig = mne.viz.plot_events(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the sensor locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to know which channel being used\n",
    "# it can show which channels are bad channels too\n",
    "fig = raw.plot_sensors(show_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data was then filtered with a bandpass keeping a frequency range between 0.5 and 30 Hz. \n",
    "# This also removed any slow signal drift in the EEG\n",
    "filt_raw = raw.copy().filter(l_freq=0.5, h_freq=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot after filter\n",
    "fig = filt_raw.plot(events=events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repairing artifacts with ICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refe:\n",
    "Repairing artifacts with ICA:\n",
    "https://mne.tools/stable/auto_tutorials/preprocessing/40_artifact_correction_ica.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = mne.preprocessing.ICA(n_components=20, max_iter='auto', random_state=97)\n",
    "ica.fit(filt_raw)\n",
    "ica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can examine the ICs to see what they captured. \n",
    "# plot_sources will show the time series of the ICs.\n",
    "filt_raw.load_data()\n",
    "# This can help us determine which ICs we need to drop\n",
    "fig = ica.plot_sources(filt_raw, show_scrollbars=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EEG Independent Component Labeling:\n",
    "https://labeling.ucsd.edu/tutorial/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also visualize the scalp field distribution of each component using plot_components.\n",
    "fig = ica.plot_components()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can plot an overlay of the original signal against \n",
    "# the reconstructed signal with the artifactual ICs excluded\n",
    "\n",
    "# eye blinks\n",
    "fig1 = ica.plot_overlay(filt_raw, exclude=[0], picks='eeg')\n",
    "# heartbeats\n",
    "fig2 = ica.plot_overlay(filt_raw, exclude=[1], picks='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica.exclude = [0, 1]  # indices chosen based on various plots above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# barplot of ICA component \"EOG match\" scores\n",
    "# We can use EOG channel to select ICA components\n",
    "eog_indices, eog_scores = ica.find_bads_eog(raw)\n",
    "fig = ica.plot_scores(eog_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compare raw_data before ica deal with artifacts and after \n",
    "\n",
    "# ica.apply() changes the Raw object in-place, so let's make a copy first:\n",
    "reconst_raw = raw.copy()\n",
    "ica.apply(reconst_raw)\n",
    "\n",
    "raw.plot()\n",
    "reconst_raw.plot()\n",
    "del reconst_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evoked responses: epoching and averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can extract epochs from the continuous data\n",
    "# get_epochs is our own method \n",
    "epochs = mne.Epochs(filt_raw, events, preload=True)\n",
    "epochs = ica.apply(epochs, exclude=ica.exclude)\n",
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the epochs graph \n",
    "fig = epochs.plot(events=events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure out which channel is good to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# letâ€™s look at our evoked responses for some conditions we care about. \n",
    "# pick any events we want ex. events 11\n",
    "events_11 = epochs['11'].average()\n",
    "# l_vis = epochs[2].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can check each channel graph for this events\n",
    "# This can help us pick the best channel we want to do training\n",
    "fig = events_11.plot(spatial_colors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalp topographies can also be obtained non-interactively with the plot_topomap method\n",
    "fig = events_11.plot_joint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think one channel is not enough, we may need combine all 61 channels. However, each subject may have different bad channels. We want to pick same channels for each subject.\n",
    "Therefore, we use MNE to determine all subjects bad channels. Here are results:\n",
    "| Subjects      | Bad Channels |\n",
    "| ----------- | ----------- |\n",
    "| P01      | P8, P10, T8      |\n",
    "| P04   | T8        |\n",
    "| P06      | Iz, FT4       |\n",
    "| P07   | None        |\n",
    "| P09      | None       |\n",
    "| P11   | T7, T8        |\n",
    "| P12      | C3, PO3       |\n",
    "| P13   | Iz        |\n",
    "| P14   | T7, F7        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According above tale, we drop this bad channel list: [C3, F7, FT4, Iz, P8, P10, PO3, T7, T8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can drop this bad channel list, and create a good channel list\n",
    "bad_channel_list = ['C3', 'F7', 'FT4', 'Iz', 'P8', 'P10', 'PO3', 'T7', 'T8', 'EXG1', 'EXG2', 'EXG3', 'EXG4', 'EXG5', 'EXG6', 'STI 014']\n",
    "all_channel_list = raw.ch_names\n",
    "good_channel = [i for i in all_channel_list if i not in bad_channel_list]\n",
    "print('Channels length: '+ str(len(good_channel)))\n",
    "good_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after we pick the channel\n",
    "# check more specific info for this channel during events <11>\n",
    "# for example, we pick channel Pz\n",
    "epochs['11'].plot_image(picks=['Pz'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Get the Data We Need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will use P01 subject to show how we get data for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, we write some helper function to help us deal with some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_useless_events(events):\n",
    "  \"\"\"\n",
    "    1. drop non-music events,ex:1000,1111,2001\n",
    "    2. drop condition 4\n",
    "  \"\"\"\n",
    "  # drop >= 1000\n",
    "  events = [i for i in events if not int(i) >= 1000]\n",
    "\n",
    "  result = [ele for ele in events if not ele.endswith(\"4\")]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_events(epochs, channels, events):\n",
    "  \"\"\"\n",
    "   Each events will repeat 5 times for each subject, \n",
    "   so we first average all 5 repeat events data to 1.\n",
    "   Next, we average all 56 good channels to 1.\n",
    "   return result back\n",
    "  \"\"\"\n",
    "  epochs = epochs.copy()\n",
    "  result = {}\n",
    "  for event in events:\n",
    "    epochs_avg = epochs[event].average()\n",
    "    epochs_avg_channels = epochs_avg.copy().pick_channels(channels)\n",
    "    data = epochs_avg_channels.get_data()\n",
    "    # average all 56 channels\n",
    "    result[event] = data.mean(axis=0)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which events do we need to predict?\n",
    "event_id = drop_useless_events(epochs.event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save result to events_dic_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# hide output\n",
    "events_dic_avg = avg_events(epochs, good_channel, event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each events has 359 points. Data Type Dict, Key: events ID, Value: List of 359 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example events 11 with conditons 2\n",
    "# print first ten\n",
    "print(events_dic_avg['112'][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize the number of points\n",
    "Minimize the number of points in each events from 359 to 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_event(events_dic):\n",
    "    result = {}\n",
    "    for key in events_dic_avg:\n",
    "        point_list = []\n",
    "        points = events_dic_avg[key]\n",
    "        splits = np.array_split(points, 60)\n",
    "        for group in splits:\n",
    "            ave = sum(group)/len(group)\n",
    "            point_list.append(ave)\n",
    "        result[key] = point_list\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dic_avg_min = minimize_event(events_dic_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each events has 60 points. Data Type Dict, Key: events ID, Value: List of 60 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dic_avg_min['11'])\n",
    "print(len(events_dic_avg_min['112']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get data for multiple subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having only one subject's data is clearly not enough for training data. After we get the data of the first subject, we need to repeat the previous steps to get the data of several more subjects to help us complete the subsequent training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the article \"Toward Studying Music Cognition with Information Retrieval Techniques: Lessons Learned from the OpenMIIR Initiative\", it meations that \" one participant was excluded for the experiments described in this paper because of a considerable number of trials with movement artifacts due to coughing.\"\\\n",
    "We check each subject data plot and then figure out subject P05 should be dropped from our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P05_raw = read_fif('P05')\n",
    "# P05_raw.plot()\n",
    "# del P05_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have 3 train subjects, and 6 test subjects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_subjects = ['P01', 'P04', 'P06'] \n",
    "train_subjects = ['P01', 'P04'] \n",
    "# test_subjects = ['P07', 'P09', 'P11', 'P12', 'P13', 'P14']\n",
    "test_subjects = ['P07']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We integrate the steps of geting data into one function called whole_process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whole_process(name, chs):\n",
    "    #1.Get dataset\n",
    "    raw = read_fif(name)\n",
    "\n",
    "    #2. Get events of the dataset\n",
    "    events = mne.find_events(raw)\n",
    "\n",
    "    #3. Filter\n",
    "    filt_raw = raw.copy().filter(l_freq=0.5, h_freq=30)\n",
    "\n",
    "    #4. Repairing artifacts with ICA\n",
    "    ica = mne.preprocessing.ICA(n_components=20, max_iter='auto', random_state=97)\n",
    "    ica.fit(filt_raw)\n",
    "\n",
    "    ica.exclude = [0, 1]\n",
    "\n",
    "    #5. Evoked responses: epoching and averaging\n",
    "    # Now we can extract epochs from the continuous data\n",
    "    # get_epochs is our own method \n",
    "    epochs = mne.Epochs(filt_raw, events, preload=True)\n",
    "    epochs = ica.apply(epochs, exclude=ica.exclude)\n",
    "\n",
    "    #6. Get the data we need\n",
    "    channels = ['Pz']\n",
    "    # Drop useless non-music events like 1000, 1111 and events with condition 4\n",
    "    event_id = drop_useless_events(epochs.event_id)\n",
    "    # Get each events average data for channel Pz and save result to events_dic_avg\n",
    "    events_dic_avg = avg_events(epochs, chs, event_id)\n",
    "    # Minimize the number of points in each events from 359 to 60 and save result to result\n",
    "    result = minimize_event(events_dic_avg)\n",
    "    del raw, filt_raw\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dic_avg_04 = whole_process('P04', good_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events_dic_avg_06 = whole_process('P06',good_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dic_avg_04['11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(events_dic_avg_06['11'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture \n",
    "# # hide output\n",
    "# train_dict = {}\n",
    "# test_dict = {}\n",
    "# # first deal with train dict\n",
    "# for t in train_subjects:\n",
    "#   # we already have P01 data skip it\n",
    "#   if t == 'P01':\n",
    "#     train_dict[t] = events_dic_avg_min\n",
    "#   else:\n",
    "#     train_dict[t] = whole_process(t, good_channel)\n",
    "\n",
    "# # then deal with test dict\n",
    "# for s in test_subjects:\n",
    "#   # we already have P01 data skip it\n",
    "#   test_dict[s] = whole_process(s, good_channel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_dict.keys())\n",
    "# print(test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 6))\n",
    "# x = np.arange(0, 60, 1)\n",
    "# y = train_dict['P04']['11']\n",
    "# z = test_dict['P07']['11']\n",
    "\n",
    "# ax.plot(y, color='blue', label='Train P04 event 11')\n",
    "# ax.plot(z, color='black', label='Test P07 event 11')\n",
    "\n",
    "# plt.xlim([25, 50])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## delelte after we done the part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "\n",
    "# with open('train.json', 'w') as fp:\n",
    "#     json.dump(train_dict, fp)\n",
    "\n",
    "# with open('test.json', 'w') as fp:\n",
    "#     json.dump(test_dict, fp)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "98b53e5711c63bc4533211ffaf303b16c17d59e4be68476b9c0d4416e252f345"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cogs189': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
